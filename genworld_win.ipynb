{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0e8289f-e2f8-43d4-bfd4-b0913edf0f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import spaces\n",
    "from gym import Env\n",
    "import random\n",
    "import numpy as np\n",
    "from threading import Thread\n",
    "import threading\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv,VecFrameStack,StackedObservations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd282224-20ee-4bb0-85e8-82a65cb6538a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for thread in threading.enumerate(): \n",
    "#     print(thread.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f55b243-bf59-4ac8-93c8-e001b25737b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for thread in threading.enumerate(): \n",
    "#     print(thread.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e0c3d3-6686-4413-b5be-f9bd31ad73ab",
   "metadata": {},
   "source": [
    "### Agent-based RL in Simple Worlds with windowing and Meta-RL\n",
    "\n",
    "- using window of states in case where velocity is masked\n",
    "- can use meta-RL: **TBD test with varying physics in a CL setting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72d807a9-feba-4fbe-bc32-9b405ff67844",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedPole(Env):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.env=gym.make('CartPole-v1')\n",
    "        self.action_space=self.env.action_space\n",
    "        self.observation_space=self.env.observation_space\n",
    "    def reset(self):\n",
    "        obs=self.env.reset()\n",
    "        # print(obs)\n",
    "        obs[1]=0\n",
    "        obs[3]=0\n",
    "        return obs\n",
    "    def step(self,action):\n",
    "        obs, rewards, dones, info = self.env.step(action)\n",
    "        # print(obs)\n",
    "        obs[1]=0\n",
    "        obs[3]=0\n",
    "        return obs, rewards, dones, info\n",
    "    def render(self,mode=\"human\"):\n",
    "        self.env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c175c769-e996-4efc-a2e3-e13cfb50c158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# env = gym.make(\"CartPole-v1\")\n",
    "# env = gym.make('MountainCar-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a22bdc97-6e73-4c6f-80c7-55e3bf56e3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = MaskedPole()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6517152-bd6d-4d36-a5b6-a8b95f2d100c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from aiagentbase.ipynb\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "from aiagentbase import AIAgent,Controller,Memory,Perception,Actor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20e9f4fa-0689-4463-9fdf-48908932a18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenWorld():\n",
    "    def __init__(self,env):\n",
    "        self.env=env\n",
    "        self.test_episodes=[]\n",
    "        self.world_over=False\n",
    "    def stop(self):\n",
    "        self.world_over=True\n",
    "    def run(self,agent=None,n_episodes=10,episode_maxlen=10):\n",
    "        agent.observation_space=env.observation_space\n",
    "        if 'training' not in agent.__dict__: agent.training=False\n",
    "        if agent.training: testing=False \n",
    "        else: testing=True\n",
    "        if agent.training: print('Starting Training time: ',agent.time)\n",
    "        for episode in range(n_episodes):\n",
    "            # print('CartAgent','starting episode')\n",
    "            state=self.env.reset()\n",
    "            agent.begin()\n",
    "            # print(agent.time)#,agent.ep)\n",
    "            for t in range(episode_maxlen):\n",
    "                # env.render(mode='rgb_array')\n",
    "                action=agent.act(state)\n",
    "                # print(episode,t,'Action: ', action)\n",
    "                state, reward, done, info = env.step(action)\n",
    "                agent.reward((reward,done,info))\n",
    "                # print(episode,t,'Reward sent: ', reward)\n",
    "                if done:\n",
    "                    break\n",
    "            if self.world_over:break\n",
    "            if not agent.training: self.test_episodes+=[episode]\n",
    "            if not agent.training and not testing: \n",
    "                print('Training Over at time: ',agent.time)\n",
    "                testing=True\n",
    "        print('Testing Done time: ', agent.time, ' Reward: ', agent.avg_rew())\n",
    "        return agent.avg_rew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec537ae8-fbf6-4c49-b16c-031b37228142",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Doesnt use AIAgent Architecture Classes but implements the same interface - for initial testing\n",
    "class RandomAgent():\n",
    "    def __init__(self,action_space):\n",
    "        self.action_space=action_space\n",
    "        self.tot_rew=0\n",
    "        self.rewL=[]\n",
    "    def act(self,state):\n",
    "        action = self.action_space.sample()\n",
    "        return action\n",
    "    def reward(self,rew):\n",
    "        self.tot_rew+=rew[0]\n",
    "    def begin(self,state):\n",
    "        self.rewL+=[self.tot_rew]\n",
    "    def avg_rew(self):\n",
    "        return sum(self.rewL)/len(self.rewL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a95733e-f863-432b-ac20-753d221e6fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomAIAgent(AIAgent):\n",
    "    def __init__(self,action_space):\n",
    "        super().__init__()\n",
    "        self.actor=self.Actor(parent=self)\n",
    "        self.action_space=action_space\n",
    "        self.tot_rew=0\n",
    "        self.rewL=[]\n",
    "        \n",
    "    class Actor(Actor):\n",
    "        def __init__(self,parent): \n",
    "            super().__init__(parent=parent)\n",
    "        def call_model(self,state):\n",
    "        ##Overriding AIAgent.Model\n",
    "            action = self.parent.action_space.sample()\n",
    "            return action\n",
    "        def compute_reward(self,reward):\n",
    "            return reward[0]\n",
    "    \n",
    "    def reward(self,rew):\n",
    "        ##Augmenting AIAgent\n",
    "        self.tot_rew+=rew[0]\n",
    "        return super().reward(rew)\n",
    "    def begin(self):\n",
    "        ##Augmenting AIAgent\n",
    "        self.rewL+=[self.tot_rew]\n",
    "        super().begin()\n",
    "    def avg_rew(self):\n",
    "        return sum(self.rewL)/len(self.rewL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d01edb66-b700-4f8b-a922-069b1de00c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent=RandomAIAgent(env.action_space)\n",
    "agent.training=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9712783c-fd5a-420a-9b27-91f2c5a28e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.debug=False\n",
    "agent.use_memory=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c43d9c18-d92e-478a-8eff-dd68f0af3d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.limit_memory=True\n",
    "agent.memory.limit_perceptual=2\n",
    "agent.memory.limit_sar=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c30d921c-8d50-4e65-aed8-6f81caaee243",
   "metadata": {},
   "outputs": [],
   "source": [
    "world=GenWorld(env=env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7212bfc0-f260-4309-b12c-87e11fa70645",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.tot_rew,agent.rewL,agent.ep=0,[],[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "24d0adf9-f667-49a4-a141-a60d9d595ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "worldthread=Thread(name='world',target=world.run,args=(agent,1000,200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f854c490-8ed2-4f50-9e46-8627525e843e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Done time:  22339  Reward:  11269.68\n"
     ]
    }
   ],
   "source": [
    "worldthread.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d2c948d-b588-48ac-8700-eb0c0155c90d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.269680000000001"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.avg_rew()/len(agent.ep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b8644cbd-6139-491d-8f12-720a4b619e07",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# world.run(agent,10,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "45180a22-fbfb-4982-b123-dd2ddbbe84d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# agent.memory.perceptual_memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e24475-66fc-4544-a0fe-20297b9246ac",
   "metadata": {},
   "source": [
    "### Training an AI Agent's Model using Generic RL Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "afefe229-241d-42fb-b5a2-0fe4b4f36c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Thread\n",
    "import threading\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "52cd9f07-62c7-4d48-af53-641fbe1ee17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from queue import Queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cae673aa-2a03-4f7e-b067-e22eb58846cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiagentbase import RLAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7243708f-daf6-4305-a0b0-11fa82153781",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_steps=30000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7f938dfc-36bd-4e18-87c0-584c3c8c0f80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "agent=RLAgent(algoclass=PPO,action_space=env.action_space,observation_space=env.observation_space,\n",
    "              verbose=1,win=4,soclass=StackedObservations,metarl=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "44edef18-00b7-4098-96f8-01f51bccc195",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.debug=False\n",
    "agent.use_memory=True\n",
    "agent.training=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d1cce67f-0995-42fa-b1a1-1753133a37f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.rewL=[]\n",
    "agent.tot_rew=0\n",
    "agent.ep=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e6fd4736-40ee-4be8-9d65-95804512b2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if agent.training: agent.start(training_steps=training_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bb1e7d8e-eae8-43f4-98b2-28f652813c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "world=GenWorld(env=env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "825ee6db-c404-4453-a405-c2cf8c54804b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# worldthread=Thread(name='world',target=world.run,args=(agent,2000,200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c295f9e2-c817-46d1-9078-c2135216f80b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# worldthread.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "86ab4c36-0aa9-44d5-bdb5-83d701f63faa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training time:  0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 24.5     |\n",
      "|    ep_rew_mean     | 24.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 1437     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 25.5        |\n",
      "|    ep_rew_mean          | 25.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1532        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 2           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007078876 |\n",
      "|    clip_fraction        | 0.0319      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.69       |\n",
      "|    explained_variance   | -0.000656   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 10.5        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.00832    |\n",
      "|    value_loss           | 59.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 26.6         |\n",
      "|    ep_rew_mean          | 26.6         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1629         |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 3            |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060328864 |\n",
      "|    clip_fraction        | 0.0337       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.674       |\n",
      "|    explained_variance   | -0.00679     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 23.1         |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00806     |\n",
      "|    value_loss           | 46.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30.6         |\n",
      "|    ep_rew_mean          | 30.6         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1719         |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 4            |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031523863 |\n",
      "|    clip_fraction        | 0.00796      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.662       |\n",
      "|    explained_variance   | 0.00385      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 32.1         |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.00267     |\n",
      "|    value_loss           | 60.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 32.6         |\n",
      "|    ep_rew_mean          | 32.6         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1414         |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 7            |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032271643 |\n",
      "|    clip_fraction        | 0.0316       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.624       |\n",
      "|    explained_variance   | 0.0395       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 34.4         |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.00604     |\n",
      "|    value_loss           | 67.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 41.6         |\n",
      "|    ep_rew_mean          | 41.6         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1434         |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 8            |\n",
      "|    total_timesteps      | 12288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024483418 |\n",
      "|    clip_fraction        | 0.0129       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.606       |\n",
      "|    explained_variance   | 0.0704       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 34.4         |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.00372     |\n",
      "|    value_loss           | 72.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 46.5        |\n",
      "|    ep_rew_mean          | 46.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1492        |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 9           |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003172257 |\n",
      "|    clip_fraction        | 0.0159      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.588      |\n",
      "|    explained_variance   | 0.123       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 33.3        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.00508    |\n",
      "|    value_loss           | 74.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 49.3         |\n",
      "|    ep_rew_mean          | 49.3         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1527         |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 10           |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047345087 |\n",
      "|    clip_fraction        | 0.0216       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.563       |\n",
      "|    explained_variance   | 0.0779       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 49.7         |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -0.00612     |\n",
      "|    value_loss           | 92.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 61           |\n",
      "|    ep_rew_mean          | 61           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1572         |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 11           |\n",
      "|    total_timesteps      | 18432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070382506 |\n",
      "|    clip_fraction        | 0.0378       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.565       |\n",
      "|    explained_variance   | 0.257        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 62.9         |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.00708     |\n",
      "|    value_loss           | 79.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 75.4         |\n",
      "|    ep_rew_mean          | 75.4         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1609         |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 12           |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054671755 |\n",
      "|    clip_fraction        | 0.0393       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.549       |\n",
      "|    explained_variance   | 0.227        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 33.7         |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.00575     |\n",
      "|    value_loss           | 75           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 89.9        |\n",
      "|    ep_rew_mean          | 89.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1638        |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 13          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008553028 |\n",
      "|    clip_fraction        | 0.0822      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.556      |\n",
      "|    explained_variance   | 0.463       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 40.1        |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0085     |\n",
      "|    value_loss           | 70.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 103         |\n",
      "|    ep_rew_mean          | 103         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1668        |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 14          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009011384 |\n",
      "|    clip_fraction        | 0.0726      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.56       |\n",
      "|    explained_variance   | 0.586       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 24          |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.00717    |\n",
      "|    value_loss           | 63          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 116         |\n",
      "|    ep_rew_mean          | 116         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1692        |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 15          |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006228514 |\n",
      "|    clip_fraction        | 0.0473      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.549      |\n",
      "|    explained_variance   | 0.556       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 26.9        |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.00556    |\n",
      "|    value_loss           | 82.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 135         |\n",
      "|    ep_rew_mean          | 135         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1712        |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 16          |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004405059 |\n",
      "|    clip_fraction        | 0.0294      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.549      |\n",
      "|    explained_variance   | 0.335       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 16.4        |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0021     |\n",
      "|    value_loss           | 94.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 147         |\n",
      "|    ep_rew_mean          | 147         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1719        |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 17          |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005443518 |\n",
      "|    clip_fraction        | 0.0765      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.526      |\n",
      "|    explained_variance   | 0.4         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 33.8        |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.00621    |\n",
      "|    value_loss           | 79          |\n",
      "-----------------------------------------\n",
      "Training Over at time:  30817\n",
      "Testing Done time:  254449  Reward:  103380.909\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "103380.909"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "world.run(agent,n_episodes=2000,episode_maxlen=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4b5ea674-7858-4611-bf7e-100934aceec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent.tot_rew/len(agent.ep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "54061a8f-0775-42ce-a95f-300931b2eb4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# len(agent.logL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "04b4a528-95bd-46df-89b5-24208287a20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ed44ee84-a7ee-4c78-a177-21f84f5243bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing_len=len([agent.rewL[t] for t in world.test_episodes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e554e4c8-2681-4bd6-b805-b708fa863ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6f1c83e7-4355-453e-84f0-fb8df19e141f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# agent.rewL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b24174f7-ddec-495e-bd52-9612889571c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127.17225\n"
     ]
    }
   ],
   "source": [
    "print(np.gradient(agent.rewL).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "592b52fb-577e-4ebd-9b8d-d63b3c1680fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(np.gradient(agent.rewL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "31b82967-748a-4909-9228-8d2de329388e",
   "metadata": {},
   "outputs": [],
   "source": [
    "episodes = 500\n",
    "rewL=[]\n",
    "agent.training=False\n",
    "for episode in range(1, episodes+1):\n",
    "    done = False\n",
    "    score = 0 \n",
    "    steps=0\n",
    "    state = env.reset()\n",
    "    while not done and steps<=200:\n",
    "        action = agent.act(state)\n",
    "        state, reward, done, info = env.step(action)\n",
    "        score+=reward\n",
    "        steps+=1\n",
    "    # print('Episode:{} Score:{}'.format(episode, score))\n",
    "    rewL+=[score]\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "12ee784d-2f75-4e2f-8f8c-91ae3b607cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from matplotlib import pyplot as plt\n",
    "# import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "30e78bfe-2dda-4fe5-a39d-06c88022a710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156.234\n"
     ]
    }
   ],
   "source": [
    "print(np.array(rewL).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26254efc-9de2-479c-95ec-d9a68f5ba5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(rewL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0b11bb-5c03-4c58-9d83-29343655ddba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# PPO??"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
