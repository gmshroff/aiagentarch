{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0e8289f-e2f8-43d4-bfd4-b0913edf0f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import spaces\n",
    "import random\n",
    "from stable_baselines3 import PPO\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c175c769-e996-4efc-a2e3-e13cfb50c158",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"CartPole-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6517152-bd6d-4d36-a5b6-a8b95f2d100c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from aiagentbase.ipynb\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "from aiagentbase import AIAgent,Controller,Memory,Perception,Actor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20e9f4fa-0689-4463-9fdf-48908932a18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CartWorld():\n",
    "    def __init__(self,env):\n",
    "        self.env=env\n",
    "    def run(self,agent=None,n_episodes=30,episode_maxlen=300):\n",
    "        global world_over\n",
    "        agent.observation_space=env.observation_space\n",
    "        if 'training' not in agent.__dict__: agent.training=False\n",
    "        world_over=False\n",
    "        for episode in range(n_episodes):\n",
    "            # print('CartAgent','starting episode')\n",
    "            if world_over: break\n",
    "            state=env.reset()\n",
    "            agent.reset(state)\n",
    "            for t in range(episode_maxlen):\n",
    "                if world_over: break\n",
    "                # env.render(mode='rgb_array')\n",
    "                action=agent.act(env.state)\n",
    "                # print('TrainingEnv queues:',agent.env.print_queues())\n",
    "                next_state, reward, done, info = env.step(action)\n",
    "                agent.reward((reward,done,info))\n",
    "                # print('Monitor over:',agent.monitor.over,'TrainingEnv counter:',\n",
    "                #       agent.env.counter)\n",
    "                if done or world_over:\n",
    "                    break\n",
    "        return agent.avg_rew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec537ae8-fbf6-4c49-b16c-031b37228142",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Doesnt use AIAgent Architecture Classes but implements the same interface - for initial testing\n",
    "class RandomAgent():\n",
    "    def __init__(self,action_space):\n",
    "        self.action_space=action_space\n",
    "        self.tot_rew=0\n",
    "        self.rewL=[]\n",
    "    def act(self,state):\n",
    "        action = self.action_space.sample()\n",
    "        return action\n",
    "    def reward(self,rew):\n",
    "        self.tot_rew+=rew[0]\n",
    "    def reset(self,state):\n",
    "        self.rewL+=[self.tot_rew]\n",
    "    def avg_rew(self):\n",
    "        return sum(self.rewL)/len(self.rewL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a95733e-f863-432b-ac20-753d221e6fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomAIAgent(AIAgent):\n",
    "    def __init__(self,action_space):\n",
    "        super().__init__()\n",
    "        self.actor.call_model=self.call_model\n",
    "        self.action_space=action_space\n",
    "        self.tot_rew=0\n",
    "        self.rewL=[]\n",
    "    def call_model(self,state):\n",
    "        ##Overriding AIAgent.Model\n",
    "        action = self.action_space.sample()\n",
    "        return action\n",
    "    def reward(self,rew):\n",
    "        ##Augmenting AIAgent\n",
    "        self.tot_rew+=rew[0]\n",
    "        return super().reward(rew)\n",
    "    def reset(self,state):\n",
    "        ##Overriding AIAgent\n",
    "        self.rewL+=[self.tot_rew]\n",
    "    def avg_rew(self):\n",
    "        return sum(self.rewL)/len(self.rewL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d01edb66-b700-4f8b-a922-069b1de00c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent=RandomAIAgent(env.action_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9712783c-fd5a-420a-9b27-91f2c5a28e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.debug=True\n",
    "agent.use_memory=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da5d0351-b72d-481f-a3ea-f100ca10a4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "world=CartWorld(env=env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8644cbd-6139-491d-8f12-720a4b619e07",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percept: [-0.0226783   0.03472544 -0.03567263 -0.027099  ] key: default\n",
      "actor_state: [-0.0226783   0.03472544 -0.03567263 -0.027099  ]\n",
      "action: 0\n",
      "percept: (-0.021983794498502688, -0.1598672648368068, -0.036214612266516295, 0.25411882629275) key: default\n",
      "actor_state: (-0.021983794498502688, -0.1598672648368068, -0.036214612266516295, 0.25411882629275)\n",
      "action: 1\n",
      "percept: (-0.025181139795238824, 0.03575255775143249, -0.031132235740661294, -0.04976328122733892) key: default\n",
      "actor_state: (-0.025181139795238824, 0.03575255775143249, -0.031132235740661294, -0.04976328122733892)\n",
      "action: 1\n",
      "percept: (-0.024466088640210173, 0.23130676326991698, -0.032127501365208075, -0.35210384913235027) key: default\n",
      "actor_state: (-0.024466088640210173, 0.23130676326991698, -0.032127501365208075, -0.35210384913235027)\n",
      "action: 0\n",
      "percept: (-0.019839953374811835, 0.036656061145034585, -0.03916957834785508, -0.06972232895599811) key: default\n",
      "actor_state: (-0.019839953374811835, 0.036656061145034585, -0.03916957834785508, -0.06972232895599811)\n",
      "action: 0\n",
      "percept: (-0.019106832151911144, -0.1578830728139148, -0.04056402492697504, 0.2103496344474069) key: default\n",
      "actor_state: (-0.019106832151911144, -0.1578830728139148, -0.04056402492697504, 0.2103496344474069)\n",
      "action: 0\n",
      "percept: (-0.02226449360818944, -0.35240225818666066, -0.0363570322380269, 0.4899658401075785) key: default\n",
      "actor_state: (-0.02226449360818944, -0.35240225818666066, -0.0363570322380269, 0.4899658401075785)\n",
      "action: 1\n",
      "percept: (-0.029312538771922653, -0.1567867781343729, -0.02655771543587533, 0.18604991423845824) key: default\n",
      "actor_state: (-0.029312538771922653, -0.1567867781343729, -0.02655771543587533, 0.18604991423845824)\n",
      "action: 0\n",
      "percept: (-0.03244827433461011, -0.35151888125909503, -0.022836717151106165, 0.4702380142488014) key: default\n",
      "actor_state: (-0.03244827433461011, -0.35151888125909503, -0.022836717151106165, 0.4702380142488014)\n",
      "action: 0\n",
      "percept: (-0.03947865195979201, -0.5463109286299777, -0.013431956866130136, 0.7556364870082592) key: default\n",
      "actor_state: (-0.03947865195979201, -0.5463109286299777, -0.013431956866130136, 0.7556364870082592)\n",
      "action: 0\n",
      "percept: [ 0.01740696 -0.01040864 -0.02243132  0.0436059 ] key: default\n",
      "actor_state: [ 0.01740696 -0.01040864 -0.02243132  0.0436059 ]\n",
      "action: 0\n",
      "percept: (0.017198792009962518, -0.20520186752171687, -0.02155919882380255, 0.32912799233139145) key: default\n",
      "actor_state: (0.017198792009962518, -0.20520186752171687, -0.02155919882380255, 0.32912799233139145)\n",
      "action: 0\n",
      "percept: (0.01309475465952818, -0.4000103779964327, -0.01497663897717472, 0.6149349371137368) key: default\n",
      "actor_state: (0.01309475465952818, -0.4000103779964327, -0.01497663897717472, 0.6149349371137368)\n",
      "action: 0\n",
      "percept: (0.005094547099599526, -0.5949199007663981, -0.0026779402348999833, 0.9028634660111412) key: default\n",
      "actor_state: (0.005094547099599526, -0.5949199007663981, -0.0026779402348999833, 0.9028634660111412)\n",
      "action: 0\n",
      "percept: (-0.006803850915728436, -0.7900054739307503, 0.015379329085322841, 1.1947034629980273) key: default\n",
      "actor_state: (-0.006803850915728436, -0.7900054739307503, 0.015379329085322841, 1.1947034629980273)\n",
      "action: 0\n",
      "percept: (-0.02260396039434344, -0.9853231575072128, 0.039273398345283386, 1.4921666856024263) key: default\n",
      "actor_state: (-0.02260396039434344, -0.9853231575072128, 0.039273398345283386, 1.4921666856024263)\n",
      "action: 0\n",
      "percept: (-0.04231042354448769, -1.1809004166289379, 0.06911673205733192, 1.7968497707703552) key: default\n",
      "actor_state: (-0.04231042354448769, -1.1809004166289379, 0.06911673205733192, 1.7968497707703552)\n",
      "action: 1\n",
      "percept: (-0.06592843187706646, -0.9866168106224804, 0.10505372747273903, 1.526424316470595) key: default\n",
      "actor_state: (-0.06592843187706646, -0.9866168106224804, 0.10505372747273903, 1.526424316470595)\n",
      "action: 0\n",
      "percept: (-0.08566076808951606, -1.1828380892341799, 0.13558221380215094, 1.8499625784798346) key: default\n",
      "actor_state: (-0.08566076808951606, -1.1828380892341799, 0.13558221380215094, 1.8499625784798346)\n",
      "action: 0\n",
      "percept: (-0.10931752987419965, -1.3791669769920405, 0.17258146537174762, 2.1814924449267465) key: default\n",
      "actor_state: (-0.10931752987419965, -1.3791669769920405, 0.17258146537174762, 2.1814924449267465)\n",
      "action: 1\n",
      "percept: [-0.00682875 -0.04076622 -0.00146083  0.01629748] key: default\n",
      "actor_state: [-0.00682875 -0.04076622 -0.00146083  0.01629748]\n",
      "action: 1\n",
      "percept: (-0.007644073546905102, 0.15437664600219284, -0.001134883558561961, -0.2768459981606744) key: default\n",
      "actor_state: (-0.007644073546905102, 0.15437664600219284, -0.001134883558561961, -0.2768459981606744)\n",
      "action: 1\n",
      "percept: (-0.004556540626861246, 0.3495147698485958, -0.00667180352177545, -0.569886651127219) key: default\n",
      "actor_state: (-0.004556540626861246, 0.3495147698485958, -0.00667180352177545, -0.569886651127219)\n",
      "action: 1\n",
      "percept: (0.0024337547701106703, 0.5447296518980933, -0.01806953654431983, -0.8646639527144653) key: default\n",
      "actor_state: (0.0024337547701106703, 0.5447296518980933, -0.01806953654431983, -0.8646639527144653)\n",
      "action: 1\n",
      "percept: (0.013328347808072537, 0.7400928440703534, -0.03536281559860914, -1.1629730561746168) key: default\n",
      "actor_state: (0.013328347808072537, 0.7400928440703534, -0.03536281559860914, -1.1629730561746168)\n",
      "action: 0\n",
      "percept: (0.028130204689479604, 0.5454487754336543, -0.05862227672210148, -0.8815839912284573) key: default\n",
      "actor_state: (0.028130204689479604, 0.5454487754336543, -0.05862227672210148, -0.8815839912284573)\n",
      "action: 1\n",
      "percept: (0.039039180198152695, 0.7413159114274644, -0.07625395654667062, -1.1921050857698003) key: default\n",
      "actor_state: (0.039039180198152695, 0.7413159114274644, -0.07625395654667062, -1.1921050857698003)\n",
      "action: 1\n",
      "percept: (0.053865498426701984, 0.9373383626865064, -0.10009605826206663, -1.5076812663742194) key: default\n",
      "actor_state: (0.053865498426701984, 0.9373383626865064, -0.10009605826206663, -1.5076812663742194)\n",
      "action: 0\n",
      "percept: (0.07261226568043211, 0.7435623434540309, -0.13024968358955102, -1.24785126012433) key: default\n",
      "actor_state: (0.07261226568043211, 0.7435623434540309, -0.13024968358955102, -1.24785126012433)\n",
      "action: 1\n",
      "percept: (0.08748351254951273, 0.9400913174613954, -0.15520670879203763, -1.5783328960360539) key: default\n",
      "actor_state: (0.08748351254951273, 0.9400913174613954, -0.15520670879203763, -1.5783328960360539)\n",
      "action: 0\n",
      "percept: [ 0.02298373 -0.02971176  0.00270717  0.0352748 ] key: default\n",
      "actor_state: [ 0.02298373 -0.02971176  0.00270717  0.0352748 ]\n",
      "action: 1\n",
      "percept: (0.02238949640492722, 0.16537126844850297, 0.0034126619901483574, -0.2565527551008595) key: default\n",
      "actor_state: (0.02238949640492722, 0.16537126844850297, 0.0034126619901483574, -0.2565527551008595)\n",
      "action: 1\n",
      "percept: (0.025696921773897277, 0.3604443303871852, -0.0017183931118688331, -0.5481573234289541) key: default\n",
      "actor_state: (0.025696921773897277, 0.3604443303871852, -0.0017183931118688331, -0.5481573234289541)\n",
      "action: 0\n",
      "percept: (0.032905808381640984, 0.1653465618018315, -0.012681539580447914, -0.2560163099515469) key: default\n",
      "actor_state: (0.032905808381640984, 0.1653465618018315, -0.012681539580447914, -0.2560163099515469)\n",
      "action: 1\n",
      "percept: (0.03621273961767761, 0.36064725638768247, -0.017801865779478853, -0.5526720684446614) key: default\n",
      "actor_state: (0.03621273961767761, 0.36064725638768247, -0.017801865779478853, -0.5526720684446614)\n",
      "action: 0\n",
      "percept: (0.043425684745431264, 0.16577976958990023, -0.028855307148372082, -0.2656506252026123) key: default\n",
      "actor_state: (0.043425684745431264, 0.16577976958990023, -0.028855307148372082, -0.2656506252026123)\n",
      "action: 1\n",
      "percept: (0.046741280137229266, 0.3613014234193017, -0.034168319652424325, -0.5672932997940296) key: default\n",
      "actor_state: (0.046741280137229266, 0.3613014234193017, -0.034168319652424325, -0.5672932997940296)\n",
      "action: 1\n",
      "percept: (0.0539673086056153, 0.5568855899563532, -0.04551418564830492, -0.8705418431295231) key: default\n",
      "actor_state: (0.0539673086056153, 0.5568855899563532, -0.04551418564830492, -0.8705418431295231)\n",
      "action: 0\n",
      "percept: (0.06510502040474236, 0.3624112952966203, -0.06292502251089538, -0.592509046222836) key: default\n",
      "actor_state: (0.06510502040474236, 0.3624112952966203, -0.06292502251089538, -0.592509046222836)\n",
      "action: 0\n",
      "percept: (0.07235324631067477, 0.16822404927684378, -0.0747752034353521, -0.3202924091771738) key: default\n",
      "actor_state: (0.07235324631067477, 0.16822404927684378, -0.0747752034353521, -0.3202924091771738)\n",
      "action: 1\n",
      "percept: [ 0.01427706 -0.01481687  0.04280987 -0.03910385] key: default\n",
      "actor_state: [ 0.01427706 -0.01481687  0.04280987 -0.03910385]\n",
      "action: 1\n",
      "percept: (0.013980718323197723, 0.17966587502907244, 0.04202779447495189, -0.3179784262315787) key: default\n",
      "actor_state: (0.013980718323197723, 0.17966587502907244, 0.04202779447495189, -0.3179784262315787)\n",
      "action: 0\n",
      "percept: (0.01757403582377917, -0.016028684708802005, 0.03566822595032032, -0.012343260781771725) key: default\n",
      "actor_state: (0.01757403582377917, -0.016028684708802005, 0.03566822595032032, -0.012343260781771725)\n",
      "action: 0\n",
      "percept: (0.01725346212960313, -0.21164352948313933, 0.03542136073468489, 0.291376612038186) key: default\n",
      "actor_state: (0.01725346212960313, -0.21164352948313933, 0.03542136073468489, 0.291376612038186)\n",
      "action: 0\n",
      "percept: (0.013020591539940344, -0.4072521663184604, 0.041248892975448606, 0.5950172204332738) key: default\n",
      "actor_state: (0.013020591539940344, -0.4072521663184604, 0.041248892975448606, 0.5950172204332738)\n",
      "action: 1\n",
      "percept: (0.004875548213571135, -0.2127310737749851, 0.05314923738411408, 0.3156075112683117) key: default\n",
      "actor_state: (0.004875548213571135, -0.2127310737749851, 0.05314923738411408, 0.3156075112683117)\n",
      "action: 0\n",
      "percept: (0.0006209267380714329, -0.408568225043375, 0.05946138760948032, 0.6245669492173884) key: default\n",
      "actor_state: (0.0006209267380714329, -0.408568225043375, 0.05946138760948032, 0.6245669492173884)\n",
      "action: 1\n",
      "percept: (-0.007550437762796066, -0.21432460554758495, 0.07195272659382809, 0.35118780054286847) key: default\n",
      "actor_state: (-0.007550437762796066, -0.21432460554758495, 0.07195272659382809, 0.35118780054286847)\n",
      "action: 0\n",
      "percept: (-0.011836929873747765, -0.4103921099991904, 0.07897648260468546, 0.665663929051821) key: default\n",
      "actor_state: (-0.011836929873747765, -0.4103921099991904, 0.07897648260468546, 0.665663929051821)\n",
      "action: 1\n",
      "percept: (-0.020044772073731572, -0.216452314805715, 0.09228976118572188, 0.3988559641718816) key: default\n",
      "actor_state: (-0.020044772073731572, -0.216452314805715, 0.09228976118572188, 0.3988559641718816)\n",
      "action: 0\n",
      "percept: [ 0.01102513 -0.03943618 -0.01091954 -0.04675063] key: default\n",
      "actor_state: [ 0.01102513 -0.03943618 -0.01091954 -0.04675063]\n",
      "action: 0\n",
      "percept: (0.010236409704815212, -0.23439986465051377, -0.011854555269885601, 0.24246717984957997) key: default\n",
      "actor_state: (0.010236409704815212, -0.23439986465051377, -0.011854555269885601, 0.24246717984957997)\n",
      "action: 1\n",
      "percept: (0.0055484124118049365, -0.039110605617026506, -0.007005211672894002, -0.05393128349114648) key: default\n",
      "actor_state: (0.0055484124118049365, -0.039110605617026506, -0.007005211672894002, -0.05393128349114648)\n",
      "action: 0\n",
      "percept: (0.004766200299464406, -0.2341314147633976, -0.008083837342716931, 0.23653323717971028) key: default\n",
      "actor_state: (0.004766200299464406, -0.2341314147633976, -0.008083837342716931, 0.23653323717971028)\n",
      "action: 0\n",
      "percept: (8.357200419645446e-05, -0.42913694579789596, -0.003353172599122725, 0.5266553540112854) key: default\n",
      "actor_state: (8.357200419645446e-05, -0.42913694579789596, -0.003353172599122725, 0.5266553540112854)\n",
      "action: 1\n",
      "percept: (-0.008499166911761466, -0.23396797347409012, 0.007179934481102983, 0.23291771045306525) key: default\n",
      "actor_state: (-0.008499166911761466, -0.23396797347409012, 0.007179934481102983, 0.23291771045306525)\n",
      "action: 0\n",
      "percept: (-0.013178526381243269, -0.42919177552708554, 0.01183828869016429, 0.5278567481119136) key: default\n",
      "actor_state: (-0.013178526381243269, -0.42919177552708554, 0.01183828869016429, 0.5278567481119136)\n",
      "action: 1\n",
      "percept: (-0.02176236189178498, -0.2342383678819369, 0.02239542365240256, 0.23892750330609236) key: default\n",
      "actor_state: (-0.02176236189178498, -0.2342383678819369, 0.02239542365240256, 0.23892750330609236)\n",
      "action: 1\n",
      "percept: (-0.026447129249423718, -0.03944339285585949, 0.027173973718524407, -0.046607982826937955) key: default\n",
      "actor_state: (-0.026447129249423718, -0.03944339285585949, 0.027173973718524407, -0.046607982826937955)\n",
      "action: 0\n",
      "percept: (-0.027235997106540906, -0.2349442486965251, 0.026241814061985648, 0.25452320065780576) key: default\n",
      "actor_state: (-0.027235997106540906, -0.2349442486965251, 0.026241814061985648, 0.25452320065780576)\n",
      "action: 1\n",
      "percept: [0.04481076 0.02326621 0.04471907 0.04682339] key: default\n",
      "actor_state: [0.04481076 0.02326621 0.04471907 0.04682339]\n",
      "action: 0\n",
      "percept: (0.04527608689340692, -0.1724675019983676, 0.0456555396929227, 0.3532734629906112) key: default\n",
      "actor_state: (0.04527608689340692, -0.1724675019983676, 0.0456555396929227, 0.3532734629906112)\n",
      "action: 0\n",
      "percept: (0.041826736853439565, -0.3682079205437798, 0.052721008952734925, 0.6599962048436989) key: default\n",
      "actor_state: (0.041826736853439565, -0.3682079205437798, 0.052721008952734925, 0.6599962048436989)\n",
      "action: 1\n",
      "percept: (0.034462578442563965, -0.17385776098365158, 0.0659209330496089, 0.3843688168218999) key: default\n",
      "actor_state: (0.034462578442563965, -0.17385776098365158, 0.0659209330496089, 0.3843688168218999)\n",
      "action: 1\n",
      "percept: (0.030985423222890933, 0.020269381825762878, 0.0736083093860469, 0.11317728888402845) key: default\n",
      "actor_state: (0.030985423222890933, 0.020269381825762878, 0.0736083093860469, 0.11317728888402845)\n",
      "action: 0\n",
      "percept: (0.03139081085940619, -0.1758258900898124, 0.07587185516372746, 0.4281450023154374) key: default\n",
      "actor_state: (0.03139081085940619, -0.1758258900898124, 0.07587185516372746, 0.4281450023154374)\n",
      "action: 1\n",
      "percept: (0.027874293057609942, 0.01814412894799547, 0.08443475521003621, 0.16031194937499177) key: default\n",
      "actor_state: (0.027874293057609942, 0.01814412894799547, 0.08443475521003621, 0.16031194937499177)\n",
      "action: 1\n",
      "percept: (0.028237175636569852, 0.21196215851861763, 0.08764099419753604, -0.10458504807629049) key: default\n",
      "actor_state: (0.028237175636569852, 0.21196215851861763, 0.08764099419753604, -0.10458504807629049)\n",
      "action: 0\n",
      "percept: (0.03247641880694221, 0.015700688274919522, 0.08554929323601024, 0.21441075562575646) key: default\n",
      "actor_state: (0.03247641880694221, 0.015700688274919522, 0.08554929323601024, 0.21441075562575646)\n",
      "action: 0\n",
      "percept: (0.032790432572440596, -0.1805335253737345, 0.08983750834852537, 0.5328064252202184) key: default\n",
      "actor_state: (0.032790432572440596, -0.1805335253737345, 0.08983750834852537, 0.5328064252202184)\n",
      "action: 1\n",
      "percept: [-0.00876722  0.03929949  0.00947468  0.01399908] key: default\n",
      "actor_state: [-0.00876722  0.03929949  0.00947468  0.01399908]\n",
      "action: 0\n",
      "percept: (-0.00798122986415838, -0.15595704767544682, 0.009754657911284447, 0.30965625784201783) key: default\n",
      "actor_state: (-0.00798122986415838, -0.15595704767544682, 0.009754657911284447, 0.30965625784201783)\n",
      "action: 1\n",
      "percept: (-0.011100370817667316, 0.039024571361001736, 0.015947783068124805, 0.02006556798773229) key: default\n",
      "actor_state: (-0.011100370817667316, 0.039024571361001736, 0.015947783068124805, 0.02006556798773229)\n",
      "action: 1\n",
      "percept: (-0.010319879390447281, 0.23391422655543975, 0.01634909442787945, -0.26754329113725683) key: default\n",
      "actor_state: (-0.010319879390447281, 0.23391422655543975, 0.01634909442787945, -0.26754329113725683)\n",
      "action: 1\n",
      "percept: (-0.0056415948593384856, 0.4287990800578322, 0.010998228605134313, -0.5550250841246648) key: default\n",
      "actor_state: (-0.0056415948593384856, 0.4287990800578322, 0.010998228605134313, -0.5550250841246648)\n",
      "action: 1\n",
      "percept: (0.002934386741818158, 0.623764893102075, -0.00010227307735898201, -0.8442227023969839) key: default\n",
      "actor_state: (0.002934386741818158, 0.623764893102075, -0.00010227307735898201, -0.8442227023969839)\n",
      "action: 1\n",
      "percept: (0.015409684603859657, 0.8188882398044254, -0.01698672712529866, -1.1369377892044898) key: default\n",
      "actor_state: (0.015409684603859657, 0.8188882398044254, -0.01698672712529866, -1.1369377892044898)\n",
      "action: 1\n",
      "percept: (0.03178744939994817, 1.0142282138756724, -0.03972548290938846, -1.4348993350818378) key: default\n",
      "actor_state: (0.03178744939994817, 1.0142282138756724, -0.03972548290938846, -1.4348993350818378)\n",
      "action: 0\n",
      "percept: (0.052072013677461615, 0.819618068859262, -0.06842346961102522, -1.1548906453539551) key: default\n",
      "actor_state: (0.052072013677461615, 0.819618068859262, -0.06842346961102522, -1.1548906453539551)\n",
      "action: 0\n",
      "percept: (0.06846437505464686, 0.6254517959436134, -0.09152128251810432, -0.8844235585052906) key: default\n",
      "actor_state: (0.06846437505464686, 0.6254517959436134, -0.09152128251810432, -0.8844235585052906)\n",
      "action: 1\n",
      "percept: [-0.01943101 -0.03987448  0.01528369  0.04574357] key: default\n",
      "actor_state: [-0.01943101 -0.03987448  0.01528369  0.04574357]\n",
      "action: 1\n",
      "percept: (-0.020228498251968874, 0.1550250183697816, 0.016198557261079688, -0.24207829679757914) key: default\n",
      "actor_state: (-0.020228498251968874, 0.1550250183697816, 0.016198557261079688, -0.24207829679757914)\n",
      "action: 0\n",
      "percept: (-0.01712799788457324, -0.04032452687051505, 0.011356991325128105, 0.05566974566912486) key: default\n",
      "actor_state: (-0.01712799788457324, -0.04032452687051505, 0.011356991325128105, 0.05566974566912486)\n",
      "action: 0\n",
      "percept: (-0.01793448842198354, -0.23560746268993008, 0.012470386238510602, 0.3519141423960743) key: default\n",
      "actor_state: (-0.01793448842198354, -0.23560746268993008, 0.012470386238510602, 0.3519141423960743)\n",
      "action: 0\n",
      "percept: (-0.022646637675782143, -0.430904510151707, 0.01950866908643209, 0.6485031343532919) key: default\n",
      "actor_state: (-0.022646637675782143, -0.430904510151707, 0.01950866908643209, 0.6485031343532919)\n",
      "action: 0\n",
      "percept: (-0.03126472787881628, -0.626292728911671, 0.03247873177349793, 0.9472648773333336) key: default\n",
      "actor_state: (-0.03126472787881628, -0.626292728911671, 0.03247873177349793, 0.9472648773333336)\n",
      "action: 1\n",
      "percept: (-0.043790582457049705, -0.4316228354427395, 0.0514240293201646, 0.6649611053271874) key: default\n",
      "actor_state: (-0.043790582457049705, -0.4316228354427395, 0.0514240293201646, 0.6649611053271874)\n",
      "action: 1\n",
      "percept: (-0.052423039165904496, -0.23725248315128417, 0.06472325142670834, 0.38890299327781996) key: default\n",
      "actor_state: (-0.052423039165904496, -0.23725248315128417, 0.06472325142670834, 0.38890299327781996)\n",
      "action: 1\n",
      "percept: (-0.05716808882893018, -0.04310605088818162, 0.07250131129226474, 0.11730845921283128) key: default\n",
      "actor_state: (-0.05716808882893018, -0.04310605088818162, 0.07250131129226474, 0.11730845921283128)\n",
      "action: 0\n",
      "percept: (-0.05803020984669381, -0.23918788017115358, 0.07484748047652136, 0.4319552389761481) key: default\n",
      "actor_state: (-0.05803020984669381, -0.23918788017115358, 0.07484748047652136, 0.4319552389761481)\n",
      "action: 1\n",
      "percept: [-0.02651049  0.01872751  0.04068153  0.04694793] key: default\n",
      "actor_state: [-0.02651049  0.01872751  0.04068153  0.04694793]\n",
      "action: 1\n",
      "percept: (-0.026135940176736164, 0.21324322212925784, 0.04162048857859042, -0.2326271506895473) key: default\n",
      "actor_state: (-0.026135940176736164, 0.21324322212925784, 0.04162048857859042, -0.2326271506895473)\n",
      "action: 1\n",
      "percept: (-0.021871075734151008, 0.4077465211851344, 0.03696794556479947, -0.5118965461366314) key: default\n",
      "actor_state: (-0.021871075734151008, 0.4077465211851344, 0.03696794556479947, -0.5118965461366314)\n",
      "action: 1\n",
      "percept: (-0.01371614531044832, 0.6023287806291404, 0.026730014642066847, -0.7927044160829061) key: default\n",
      "actor_state: (-0.01371614531044832, 0.6023287806291404, 0.026730014642066847, -0.7927044160829061)\n",
      "action: 0\n",
      "percept: (-0.0016695696978655129, 0.40685026663359614, 0.010875926320408725, -0.49173370145996603) key: default\n",
      "actor_state: (-0.0016695696978655129, 0.40685026663359614, 0.010875926320408725, -0.49173370145996603)\n",
      "action: 0\n",
      "percept: (0.006467435634806409, 0.21157660668072908, 0.0010412522912094033, -0.19564307563014105) key: default\n",
      "actor_state: (0.006467435634806409, 0.21157660668072908, 0.0010412522912094033, -0.19564307563014105)\n",
      "action: 0\n",
      "percept: (0.01069896776842099, 0.016439776754103103, -0.002871609221393418, 0.09736813870166994) key: default\n",
      "actor_state: (0.01069896776842099, 0.016439776754103103, -0.002871609221393418, 0.09736813870166994)\n",
      "action: 0\n",
      "percept: (0.011027763303503052, -0.17864090046693265, -0.0009242464473600193, 0.3891436960864058) key: default\n",
      "actor_state: (0.011027763303503052, -0.17864090046693265, -0.0009242464473600193, 0.3891436960864058)\n",
      "action: 1\n",
      "percept: (0.007454945294164399, 0.016494157047244495, 0.006858627474368098, 0.09616950641617783) key: default\n",
      "actor_state: (0.007454945294164399, 0.016494157047244495, 0.006858627474368098, 0.09616950641617783)\n",
      "action: 0\n",
      "percept: (0.007784828435109289, -0.17872542002094888, 0.008782017602691655, 0.3910084052543074) key: default\n",
      "actor_state: (0.007784828435109289, -0.17872542002094888, 0.008782017602691655, 0.3910084052543074)\n",
      "action: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "45.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "world.run(agent,10,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e24475-66fc-4544-a0fe-20297b9246ac",
   "metadata": {},
   "source": [
    "### Training an AI Agent's Model using an off-the shelf RL procedure\n",
    "Create a local environment called by a Monitor thread running within Agent, which implements or\n",
    "re-uses an on-policy RL training procedure (such as PPO etc.). The env has an input and output queue. If a training flag is set, the Agent uses a ProxyModel place of its normal model to compute actions: The actor-state is placed in the env's input queue and an action is awaited from the env's output queue.\n",
    "\n",
    "The monitor starts by calling the env.reset method that waits on the input queue to receive \n",
    "and then return a state. The monitor thread computes an action on the current state and calls\n",
    "env.step(action), which places the action in the output queue and awaits a reward from the input\n",
    "queue. After receiving a reward, step again waits for the next state on the input queue.\n",
    "Once this is also received, both next stte and reward are returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "afefe229-241d-42fb-b5a2-0fe4b4f36c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from queue import Queue\n",
    "from threading import Thread\n",
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d819bbb0-dc30-46d0-9c8e-3c5cf11e74ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PPOAgent(RandomAIAgent):\n",
    "    def __init__(self,action_space,observation_space,training_steps=20000):\n",
    "        ##Augmenting AIAgent\n",
    "        # self.model=model = PPO.load('ReinforcementLearningCourse-main/Training/Saved Models/PPO_model', env=env)\n",
    "        super().__init__(action_space)\n",
    "        self.env=self.TrainingEnv(parent=self)\n",
    "        self.env.observation_space=observation_space\n",
    "        self.model=PPO('MlpPolicy', self.env, verbose=0)\n",
    "        self.monitor=self.Monitor(parent=self)\n",
    "        # self.monitorthread=Thread(target=self.monitor.run) #For dubugging\n",
    "        self.set_training(True)\n",
    "        self.monitorthread=Thread(target=self.monitor.train,args=(training_steps,))\n",
    "        self.monitorthread.start()\n",
    "        self.tot_rew=0\n",
    "        self.logL=[]\n",
    "    \n",
    "    def log(self,entry):\n",
    "        self.logL+=[entry]\n",
    "        \n",
    "    def set_training(self,value):\n",
    "        self.training=value\n",
    "        \n",
    "    class TrainingEnv(gym.Env):\n",
    "        def __init__(self,parent):\n",
    "            self.parent=parent\n",
    "            self.action_space=spaces.Discrete(2)\n",
    "            # self.observation_space=spaces.Box(\n",
    "            #     low=np.array([-4.8000002e+00, -3.4028235e+38, -4.1887903e-01, -3.4028235e+38]), \n",
    "            #     high=np.array([4.8000002e+00, 3.4028235e+38, 4.1887903e-01, 3.4028235e+38]), \n",
    "            #     shape=(4,), dtype=np.float32)\n",
    "            self.inputS=Queue() #written by act read by reset and step\n",
    "            self.outputS=Queue() #written by act read by act\n",
    "            self.rewardI=Queue() #written by act and read by step\n",
    "            self.actionO=Queue() #written by step and read by act\n",
    "            self.counter=0\n",
    "        def reset(self):\n",
    "            # print('reset')\n",
    "            state=self.inputS.get()\n",
    "            return state\n",
    "        def step(self,action):\n",
    "            # print('step')\n",
    "            self.actionO.put(action)\n",
    "            reward,done,info=self.rewardI.get()\n",
    "            next_state=self.inputS.get()\n",
    "            self.counter+=1\n",
    "            # print(self.counter,done)\n",
    "            return next_state,reward,done,info\n",
    "        def print_queues(self):\n",
    "            print('inputS',self.inputS.queue)\n",
    "            print('actionO',self.actionO.queue)\n",
    "            print('rewardI',self.rewardI.queue)\n",
    "            print('outputS',self.outputS.queue)\n",
    "             \n",
    "    class Monitor():\n",
    "        def __init__(self,parent):\n",
    "            self.parent=parent\n",
    "        def run(self):\n",
    "            state=env.reset()\n",
    "            for episode in range(600):\n",
    "                # env.render()\n",
    "                action=self.parent.env.action_space.sample()\n",
    "                next_state, reward, done, info = self.parent.env.step(action)\n",
    "                print(next_state, reward, done, info, action)\n",
    "            self.parent.monitorthread.join()\n",
    "        def train(self,training_steps):\n",
    "            global world_over\n",
    "            self.parent.model.learn(total_timesteps=training_steps)\n",
    "            print('Training Over')\n",
    "            self.parent.set_training(False)\n",
    "            self.parent.log((self.parent.training,self.parent))\n",
    "            \n",
    "    def call_model(self,state):\n",
    "        ##Overriding AIAgent\n",
    "        if self.training:\n",
    "            self.env.inputS.put(state)\n",
    "            try: action = self.env.actionO.get(timeout=5)\n",
    "            except: action=0\n",
    "        else: action, _states = self.model.predict(state)\n",
    "        return action\n",
    "    def reward(self,reward):\n",
    "        ##Augmenting AIAgent\n",
    "        if self.training: self.env.rewardI.put(reward)\n",
    "        super().reward(reward)\n",
    "    def reset(self,state):\n",
    "        ##Overriding AIAgent\n",
    "        self.rewL+=[self.tot_rew]\n",
    "        if self.training: self.env.inputS.put(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f938dfc-36bd-4e18-87c0-584c3c8c0f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent=PPOAgent(env.action_space,env.observation_space,training_steps=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "44edef18-00b7-4098-96f8-01f51bccc195",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.debug=False\n",
    "agent.use_memory=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d1cce67f-0995-42fa-b1a1-1753133a37f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.rewL=[]\n",
    "agent.tot_rew=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bb1e7d8e-eae8-43f4-98b2-28f652813c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "world=CartWorld(env=env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "de878c07-e022-4e18-96dc-52c98494bf64",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Over\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "109402.8695"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "world.run(agent,n_episodes=2000,episode_maxlen=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b4a528-95bd-46df-89b5-24208287a20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24174f7-ddec-495e-bd52-9612889571c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.gradient(agent.rewL).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592b52fb-577e-4ebd-9b8d-d63b3c1680fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.gradient(agent.rewL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b97138-511d-4bac-acac-b20f19e2c0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for thread in threading.enumerate(): \n",
    "    print(thread.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6828025a-aa04-4f34-9aa9-c20f9a405b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(agent.memory.sar_memory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502a61bf-8782-496d-8b66-fb6e1d2eb70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447f5a0d-b924-4997-b954-b35e6a77388c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
