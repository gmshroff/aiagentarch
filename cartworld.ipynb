{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0e8289f-e2f8-43d4-bfd4-b0913edf0f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import spaces\n",
    "import random\n",
    "from stable_baselines3 import PPO\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c175c769-e996-4efc-a2e3-e13cfb50c158",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"CartPole-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6517152-bd6d-4d36-a5b6-a8b95f2d100c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random_games()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20e9f4fa-0689-4463-9fdf-48908932a18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CartWorld():\n",
    "    def __init__(self,env):\n",
    "        self.env=env\n",
    "    def run(self,agent=None,n_episodes=30,episode_maxlen=300):\n",
    "        global world_over\n",
    "        agent.observation_space=env.observation_space\n",
    "        if 'training' not in agent.__dict__: agent.training=False\n",
    "        world_over=False\n",
    "        for episode in range(n_episodes):\n",
    "            # print('CartAgent','starting episode')\n",
    "            if world_over: break\n",
    "            state=env.reset()\n",
    "            agent.reset(state)\n",
    "            for t in range(episode_maxlen):\n",
    "                if world_over: break\n",
    "                # env.render(mode='rgb_array')\n",
    "                action=agent.act(env.state)\n",
    "                # print('TrainingEnv queues:',agent.env.print_queues())\n",
    "                next_state, reward, done, info = env.step(action)\n",
    "                agent.reward((reward,done,info))\n",
    "                # print('Monitor over:',agent.monitor.over,'TrainingEnv counter:',\n",
    "                #       agent.env.counter)\n",
    "                if done or world_over:\n",
    "                    break\n",
    "        return agent.avg_rew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec537ae8-fbf6-4c49-b16c-031b37228142",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomAgent():\n",
    "    def __init__(self,action_space):\n",
    "        self.action_space=action_space\n",
    "        self.tot_rew=0\n",
    "        self.rewL=[]\n",
    "    def act(self,state):\n",
    "        action = self.action_space.sample()\n",
    "        return action\n",
    "    def reward(self,rew):\n",
    "        self.tot_rew+=rew[0]\n",
    "    def reset(self,state):\n",
    "        self.rewL+=[self.tot_rew]\n",
    "    def avg_rew(self):\n",
    "        return sum(self.rewL)/len(self.rewL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9d551d8-83dd-4233-88c9-66a77eafa3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent=PPOAgent(env.action_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d01edb66-b700-4f8b-a922-069b1de00c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent=RandomAgent(env.action_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da5d0351-b72d-481f-a3ea-f100ca10a4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "world=CartWorld(env=env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8644cbd-6139-491d-8f12-720a4b619e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# world.run(agent,10,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b02561e0-e4cb-49b0-bbdb-46e647952228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent.rewL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e24475-66fc-4544-a0fe-20297b9246ac",
   "metadata": {},
   "source": [
    "### Training an AI Agent's Model using an off-the shelf RL procedure\n",
    "Create a local environment called by a Monitor thread running within Agent, which implements or\n",
    "re-uses an on-policy RL training procedure (such as PPO etc.). The env has an input and output queue. If a training flag is set, the Agent uses a ProxyModel place of its normal model to compute actions: The actor-state is placed in the env's input queue and an action is awaited from the env's output queue.\n",
    "\n",
    "The monitor starts by calling the env.reset method that waits on the input queue to receive \n",
    "and then return a state. The monitor thread computes an action on the current state and calls\n",
    "env.step(action), which places the action in the output queue and awaits a reward from the input\n",
    "queue. After receiving a reward, step again waits for the next state on the input queue.\n",
    "Once this is also received, both next stte and reward are returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "afefe229-241d-42fb-b5a2-0fe4b4f36c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from queue import Queue\n",
    "from threading import Thread\n",
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d819bbb0-dc30-46d0-9c8e-3c5cf11e74ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PPOAgent(RandomAgent):\n",
    "    def __init__(self,action_space,observation_space,training_steps=20000):\n",
    "        # self.model=model = PPO.load('ReinforcementLearningCourse-main/Training/Saved Models/PPO_model', env=env)\n",
    "        super().__init__(action_space)\n",
    "        self.env=self.TrainingEnv(parent=self)\n",
    "        self.env.observation_space=observation_space\n",
    "        self.model=PPO('MlpPolicy', self.env, verbose=0)\n",
    "        self.monitor=self.Monitor(parent=self)\n",
    "        # self.monitorthread=Thread(target=self.monitor.run) #For dubugging\n",
    "        self.set_training(True)\n",
    "        self.monitorthread=Thread(target=self.monitor.train,args=(training_steps,))\n",
    "        self.monitorthread.start()\n",
    "        self.tot_rew=0\n",
    "        self.logL=[]\n",
    "    \n",
    "    def log(self,entry):\n",
    "        self.logL+=[entry]\n",
    "        \n",
    "    def set_training(self,value):\n",
    "        self.training=value\n",
    "        \n",
    "    class TrainingEnv(gym.Env):\n",
    "        def __init__(self,parent):\n",
    "            self.parent=parent\n",
    "            self.action_space=spaces.Discrete(2)\n",
    "            # self.observation_space=spaces.Box(\n",
    "            #     low=np.array([-4.8000002e+00, -3.4028235e+38, -4.1887903e-01, -3.4028235e+38]), \n",
    "            #     high=np.array([4.8000002e+00, 3.4028235e+38, 4.1887903e-01, 3.4028235e+38]), \n",
    "            #     shape=(4,), dtype=np.float32)\n",
    "            self.inputS=Queue() #written by act read by reset and step\n",
    "            self.outputS=Queue() #written by act read by act\n",
    "            self.rewardI=Queue() #written by act and read by step\n",
    "            self.actionO=Queue() #written by step and read by act\n",
    "            self.counter=0\n",
    "        def reset(self):\n",
    "            # print('reset')\n",
    "            state=self.inputS.get()\n",
    "            return state\n",
    "        def step(self,action):\n",
    "            # print('step')\n",
    "            self.actionO.put(action)\n",
    "            reward,done,info=self.rewardI.get()\n",
    "            next_state=self.inputS.get()\n",
    "            self.counter+=1\n",
    "            # print(self.counter,done)\n",
    "            return next_state,reward,done,info\n",
    "        def print_queues(self):\n",
    "            print('inputS',self.inputS.queue)\n",
    "            print('actionO',self.actionO.queue)\n",
    "            print('rewardI',self.rewardI.queue)\n",
    "            print('outputS',self.outputS.queue)\n",
    "             \n",
    "    class Monitor():\n",
    "        def __init__(self,parent):\n",
    "            self.parent=parent\n",
    "        def run(self):\n",
    "            state=env.reset()\n",
    "            for episode in range(600):\n",
    "                # env.render()\n",
    "                action=self.parent.env.action_space.sample()\n",
    "                next_state, reward, done, info = self.parent.env.step(action)\n",
    "                print(next_state, reward, done, info, action)\n",
    "            self.parent.monitorthread.join()\n",
    "        def train(self,training_steps):\n",
    "            global world_over\n",
    "            self.parent.model.learn(total_timesteps=training_steps)\n",
    "            print('Training Over')\n",
    "            self.parent.set_training(False)\n",
    "            self.parent.log((self.parent.training,self.parent))\n",
    "        \n",
    "    def act(self,state):\n",
    "        if self.training:\n",
    "            self.env.inputS.put(state)\n",
    "            try: action = self.env.actionO.get(timeout=5)\n",
    "            except: action=0\n",
    "        else: action, _states = self.model.predict(state)\n",
    "        return action\n",
    "    def reward(self,reward):\n",
    "        if self.training: self.env.rewardI.put(reward)\n",
    "        super().reward(reward)\n",
    "    def reset(self,state):\n",
    "        self.rewL+=[self.tot_rew]\n",
    "        # self.tot_rew=0\n",
    "        if self.training: self.env.inputS.put(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7f938dfc-36bd-4e18-87c0-584c3c8c0f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent=PPOAgent(env.action_space,env.observation_space,training_steps=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d1cce67f-0995-42fa-b1a1-1753133a37f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.rewL=[]\n",
    "agent.tot_rew=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bb1e7d8e-eae8-43f4-98b2-28f652813c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "world=CartWorld(env=env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "de878c07-e022-4e18-96dc-52c98494bf64",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Over\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "114618.738"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "world.run(agent,n_episodes=2000,episode_maxlen=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "04b4a528-95bd-46df-89b5-24208287a20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b24174f7-ddec-495e-bd52-9612889571c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128.3115"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.gradient(agent.rewL).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "592b52fb-577e-4ebd-9b8d-d63b3c1680fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16673eee0>]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.gradient(agent.rewL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7b97138-511d-4bac-acac-b20f19e2c0e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MainThread\n",
      "Thread-4\n",
      "Thread-5\n",
      "Thread-6\n",
      "Thread-7\n",
      "Thread-3\n",
      "IPythonHistorySavingThread\n",
      "Thread-2\n"
     ]
    }
   ],
   "source": [
    "for thread in threading.enumerate(): \n",
    "    print(thread.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6828025a-aa04-4f34-9aa9-c20f9a405b15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m\n",
       "\u001b[0mPPO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpolicy\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mType\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstable_baselines3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mActorCriticPolicy\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0menv\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEnv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstable_baselines3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvec_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_vec_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVecEnv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlearning_rate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0003\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mn_steps\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2048\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mn_epochs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mgamma\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.99\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mgae_lambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.95\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mclip_range\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mclip_range_vf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mNoneType\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0ment_coef\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mvf_coef\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmax_grad_norm\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0muse_sde\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msde_sample_freq\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtarget_kl\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtensorboard_log\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcreate_eval_env\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpolicy_kwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mseed\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'auto'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0m_init_setup_model\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mSource:\u001b[0m        \n",
       "\u001b[0;32mclass\u001b[0m \u001b[0mPPO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOnPolicyAlgorithm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"\u001b[0m\n",
       "\u001b[0;34m    Proximal Policy Optimization algorithm (PPO) (clip version)\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Paper: https://arxiv.org/abs/1707.06347\u001b[0m\n",
       "\u001b[0;34m    Code: This implementation borrows code from OpenAI Spinning Up (https://github.com/openai/spinningup/)\u001b[0m\n",
       "\u001b[0;34m    https://github.com/ikostrikov/pytorch-a2c-ppo-acktr-gail and\u001b[0m\n",
       "\u001b[0;34m    and Stable Baselines (PPO2 from https://github.com/hill-a/stable-baselines)\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Introduction to PPO: https://spinningup.openai.com/en/latest/algorithms/ppo.html\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    :param policy: The policy model to use (MlpPolicy, CnnPolicy, ...)\u001b[0m\n",
       "\u001b[0;34m    :param env: The environment to learn from (if registered in Gym, can be str)\u001b[0m\n",
       "\u001b[0;34m    :param learning_rate: The learning rate, it can be a function\u001b[0m\n",
       "\u001b[0;34m        of the current progress remaining (from 1 to 0)\u001b[0m\n",
       "\u001b[0;34m    :param n_steps: The number of steps to run for each environment per update\u001b[0m\n",
       "\u001b[0;34m        (i.e. rollout buffer size is n_steps * n_envs where n_envs is number of environment copies running in parallel)\u001b[0m\n",
       "\u001b[0;34m        NOTE: n_steps * n_envs must be greater than 1 (because of the advantage normalization)\u001b[0m\n",
       "\u001b[0;34m        See https://github.com/pytorch/pytorch/issues/29372\u001b[0m\n",
       "\u001b[0;34m    :param batch_size: Minibatch size\u001b[0m\n",
       "\u001b[0;34m    :param n_epochs: Number of epoch when optimizing the surrogate loss\u001b[0m\n",
       "\u001b[0;34m    :param gamma: Discount factor\u001b[0m\n",
       "\u001b[0;34m    :param gae_lambda: Factor for trade-off of bias vs variance for Generalized Advantage Estimator\u001b[0m\n",
       "\u001b[0;34m    :param clip_range: Clipping parameter, it can be a function of the current progress\u001b[0m\n",
       "\u001b[0;34m        remaining (from 1 to 0).\u001b[0m\n",
       "\u001b[0;34m    :param clip_range_vf: Clipping parameter for the value function,\u001b[0m\n",
       "\u001b[0;34m        it can be a function of the current progress remaining (from 1 to 0).\u001b[0m\n",
       "\u001b[0;34m        This is a parameter specific to the OpenAI implementation. If None is passed (default),\u001b[0m\n",
       "\u001b[0;34m        no clipping will be done on the value function.\u001b[0m\n",
       "\u001b[0;34m        IMPORTANT: this clipping depends on the reward scaling.\u001b[0m\n",
       "\u001b[0;34m    :param ent_coef: Entropy coefficient for the loss calculation\u001b[0m\n",
       "\u001b[0;34m    :param vf_coef: Value function coefficient for the loss calculation\u001b[0m\n",
       "\u001b[0;34m    :param max_grad_norm: The maximum value for the gradient clipping\u001b[0m\n",
       "\u001b[0;34m    :param use_sde: Whether to use generalized State Dependent Exploration (gSDE)\u001b[0m\n",
       "\u001b[0;34m        instead of action noise exploration (default: False)\u001b[0m\n",
       "\u001b[0;34m    :param sde_sample_freq: Sample a new noise matrix every n steps when using gSDE\u001b[0m\n",
       "\u001b[0;34m        Default: -1 (only sample at the beginning of the rollout)\u001b[0m\n",
       "\u001b[0;34m    :param target_kl: Limit the KL divergence between updates,\u001b[0m\n",
       "\u001b[0;34m        because the clipping is not enough to prevent large update\u001b[0m\n",
       "\u001b[0;34m        see issue #213 (cf https://github.com/hill-a/stable-baselines/issues/213)\u001b[0m\n",
       "\u001b[0;34m        By default, there is no limit on the kl div.\u001b[0m\n",
       "\u001b[0;34m    :param tensorboard_log: the log location for tensorboard (if None, no logging)\u001b[0m\n",
       "\u001b[0;34m    :param create_eval_env: Whether to create a second environment that will be\u001b[0m\n",
       "\u001b[0;34m        used for evaluating the agent periodically. (Only available when passing string for the environment)\u001b[0m\n",
       "\u001b[0;34m    :param policy_kwargs: additional arguments to be passed to the policy on creation\u001b[0m\n",
       "\u001b[0;34m    :param verbose: the verbosity level: 0 no output, 1 info, 2 debug\u001b[0m\n",
       "\u001b[0;34m    :param seed: Seed for the pseudo random generators\u001b[0m\n",
       "\u001b[0;34m    :param device: Device (cpu, cuda, ...) on which the code should be run.\u001b[0m\n",
       "\u001b[0;34m        Setting it to auto, the code will be run on the GPU if possible.\u001b[0m\n",
       "\u001b[0;34m    :param _init_setup_model: Whether or not to build the network at the creation of the instance\u001b[0m\n",
       "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mpolicy\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mType\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mActorCriticPolicy\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0menv\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mGymEnv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mlearning_rate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSchedule\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3e-4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mn_steps\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2048\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mn_epochs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mgamma\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.99\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mgae_lambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.95\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mclip_range\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSchedule\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mclip_range_vf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSchedule\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0ment_coef\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mvf_coef\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mmax_grad_norm\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0muse_sde\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0msde_sample_freq\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mtarget_kl\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mtensorboard_log\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mcreate_eval_env\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mpolicy_kwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mseed\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"auto\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0m_init_setup_model\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPPO\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mpolicy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mn_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mgae_lambda\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgae_lambda\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0ment_coef\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ment_coef\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mvf_coef\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvf_coef\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mmax_grad_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_grad_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0muse_sde\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_sde\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0msde_sample_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msde_sample_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mtensorboard_log\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensorboard_log\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mpolicy_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpolicy_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mcreate_eval_env\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_eval_env\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0m_init_setup_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0msupported_action_spaces\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mspaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBox\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mspaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDiscrete\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mspaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMultiDiscrete\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mspaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMultiBinary\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# Sanity check, otherwise it will lead to noisy gradient and NaN\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# because of the advantage normalization\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mbatch_size\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"`batch_size` must be greater than 1. See https://github.com/DLR-RM/stable-baselines3/issues/440\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;31m# Check that `n_steps * n_envs > 1` to avoid NaN\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;31m# when doing advantage normalization\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mbuffer_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_envs\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mbuffer_size\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"`n_steps * n_envs` must be greater than 1. Currently n_steps={self.n_steps} and n_envs={self.env.num_envs}\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;31m# Check that the rollout buffer size is a multiple of the mini-batch size\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0muntruncated_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuffer_size\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mbuffer_size\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0;34mf\"You have specified a mini-batch size of {batch_size},\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0;34mf\" but because the `RolloutBuffer` is of size `n_steps * n_envs = {buffer_size}`,\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0;34mf\" after every {untruncated_batches} untruncated mini-batches,\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0;34mf\" there will be a truncated mini-batch of size {buffer_size % batch_size}\\n\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0;34mf\"We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\\n\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0;34mf\"Info: (n_steps={self.n_steps} and n_envs={self.env.num_envs})\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_range\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclip_range\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_range_vf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclip_range_vf\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_kl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_kl\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0m_init_setup_model\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m_setup_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPPO\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# Initialize schedules for policy/value clipping\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_range\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_schedule_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_range\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_range_vf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_range_vf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_range_vf\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"`clip_range_vf` must be positive, \"\u001b[0m \u001b[0;34m\"pass `None` to deactivate vf clipping\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_range_vf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_schedule_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_range_vf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"\u001b[0m\n",
       "\u001b[0;34m        Update policy using the currently gathered rollout buffer.\u001b[0m\n",
       "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# Switch to train mode (this affects batch norm / dropout)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_training_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# Update optimizer learning rate\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_learning_rate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# Compute current clip range\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mclip_range\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_range\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_progress_remaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# Optional: clip range for the value function\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_range_vf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mclip_range_vf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_range_vf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_progress_remaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mentropy_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mpg_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mclip_fractions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mcontinue_training\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# train for n_epochs epochs\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mapprox_kl_divs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;31m# Do a complete pass on the rollout buffer\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mfor\u001b[0m \u001b[0mrollout_data\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrollout_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mactions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrollout_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDiscrete\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0;31m# Convert discrete action from float to long\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0mactions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrollout_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;31m# Re-sample the noise matrix because the log_std has changed\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_sde\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_noise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_prob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentropy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_actions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrollout_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;31m# Normalize advantage\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0madvantages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrollout_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvantages\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0madvantages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0madvantages\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0madvantages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0madvantages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1e-8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;31m# ratio between old and new policy, should be one at the first iteration\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mratio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_prob\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mrollout_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mold_log_prob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;31m# clipped surrogate loss\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mpolicy_loss_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madvantages\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mratio\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mpolicy_loss_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madvantages\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mratio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mclip_range\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mclip_range\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mpolicy_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpolicy_loss_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolicy_loss_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;31m# Logging\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mpg_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpolicy_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mclip_fraction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mratio\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mclip_range\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mclip_fractions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclip_fraction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_range_vf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0;31m# No clipping\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0mvalues_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0;31m# Clip the different between old and new value\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0;31m# NOTE: this depends on the reward scaling\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0mvalues_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrollout_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mold_values\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                        \u001b[0mvalues\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mrollout_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mold_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mclip_range_vf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip_range_vf\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;31m# Value loss using the TD(gae_lambda) target\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mvalue_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrollout_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mvalue_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;31m# Entropy loss favor exploration\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;32mif\u001b[0m \u001b[0mentropy\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0;31m# Approximate entropy when no analytical form\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0mentropy_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0mentropy_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentropy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mentropy_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentropy_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpolicy_loss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ment_coef\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mentropy_loss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvf_coef\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mvalue_loss\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;31m# Calculate approximate form of reverse KL Divergence for early stopping\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;31m# see issue #417: https://github.com/DLR-RM/stable-baselines3/issues/417\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;31m# and discussion in PR #419: https://github.com/DLR-RM/stable-baselines3/pull/419\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;31m# and Schulman blog: http://joschu.net/blog/kl-approx.html\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;32mwith\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0mlog_ratio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog_prob\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mrollout_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mold_log_prob\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0mapprox_kl_div\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_ratio\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlog_ratio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0mapprox_kl_divs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapprox_kl_div\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_kl\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mapprox_kl_div\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_kl\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0mcontinue_training\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                        \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Early stopping at step {epoch} due to reaching max kl: {approx_kl_div:.2f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;31m# Optimization step\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;31m# Clip grad norm\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_grad_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontinue_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_updates\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mexplained_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexplained_variance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrollout_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrollout_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# Logs\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train/entropy_loss\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentropy_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train/policy_gradient_loss\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpg_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train/value_loss\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train/approx_kl\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapprox_kl_divs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train/clip_fraction\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclip_fractions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train/loss\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train/explained_variance\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexplained_var\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"log_std\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train/std\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_std\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train/n_updates\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_updates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"tensorboard\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train/clip_range\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip_range\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_range_vf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train/clip_range_vf\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip_range_vf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mMaybeCallback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mlog_interval\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0meval_env\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mGymEnv\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0meval_freq\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mn_eval_episodes\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mtb_log_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"PPO\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0meval_log_path\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mreset_num_timesteps\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"PPO\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPPO\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mlog_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlog_interval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0meval_env\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_env\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0meval_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mn_eval_episodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_eval_episodes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mtb_log_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtb_log_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0meval_log_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_log_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mreset_num_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset_num_timesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m           /opt/homebrew/Caskroom/miniforge/base/envs/py38algo/lib/python3.8/site-packages/stable_baselines3/ppo/ppo.py\n",
       "\u001b[0;31mType:\u001b[0m           ABCMeta\n",
       "\u001b[0;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "PPO??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502a61bf-8782-496d-8b66-fb6e1d2eb70d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
